{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f096d4f5",
   "metadata": {},
   "source": [
    "Initializing Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e2020a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabula\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd84c424",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81df9cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracts key words on the pdf\n",
    "#Returns a data frame of keywords and it's location on the pdf, with page numbers\n",
    "#Step 1 in table parsing\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Iterable, Any\n",
    "\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer\n",
    "\n",
    "\n",
    "def extract_to_df(pages: Any):\n",
    "    cols = [\"Page\",\"Text\", \"x_1\", \"y_1\", \"x_2\", \"y_2\"]\n",
    "    words = [\"Last Raced\", \"Fractional Times\", \"Past Performance Running Line Preview\", \"Fin\", \"Trainers\"]\n",
    "    text_loc_df = pd.DataFrame(columns = cols)\n",
    "    \n",
    "    page_counter = 0\n",
    "    for page_layout in pages:\n",
    "        page_counter += 1\n",
    "        word_counter = 0\n",
    "        for element in page_layout:\n",
    "            if isinstance(element, LTTextContainer):\n",
    "                element_text = element.get_text()\n",
    "                for word in words:\n",
    "                    if(element_text.__contains__(word)):\n",
    "                        loc_nums = []\n",
    "                        for num in element.bbox:\n",
    "                            loc_nums.append(num) #Adding binding box numbers\n",
    "                        text_loc_df.loc[len(text_loc_df.index)] = [page_counter,\n",
    "                                                                     word,\n",
    "                                                                     loc_nums[0], \n",
    "                                                                     loc_nums[1], \n",
    "                                                                     loc_nums[2], \n",
    "                                                                     loc_nums[3]]\n",
    "    return text_loc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "194fbb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting pixel location of words per page\n",
    "#Step 2 in table parsing\n",
    "\n",
    "def create_text_loc_df(page_num,df):\n",
    "    text_loc_df = df.loc[df['Page'] == page_num] \n",
    "\n",
    "    #Saving only last instance of fin; Lowest y_1\n",
    "\n",
    "    fin_df = text_loc_df.loc[text_loc_df['Text'] == \"Fin\"] #df with only Fin\n",
    "    fin_df = fin_df.sort_values(by=['y_1']) #Sort by y_1 descending\n",
    "    fin_row = fin_df.iloc[0] #Save 1st row\n",
    "    text_loc_df = text_loc_df.loc[text_loc_df['Text'] != \"Fin\"] #Delete Fin rows\n",
    "    #text_loc_df = pd.concat(text_loc_df,fin_row.to_frame(),ignore_index=True) #Append right Fin row\n",
    "    text_loc_df.loc[len(text_loc_df) + 1] = fin_row\n",
    "\n",
    "    #Resort table by index\n",
    "    text_loc_df = text_loc_df.sort_index()\n",
    "    return text_loc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecd65de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating table location dataframe\n",
    "#Converts to inches and then pdf_location for tabula\n",
    "#Step 3 of table parsing\n",
    "\n",
    "def table_location_to_df(page_num,text_loc_df):\n",
    "    df = text_loc_df\n",
    "    cols = [\"Page\",\"Table\",'Top','Left','Bottom','Right']\n",
    "    table_loc_df = pd.DataFrame(columns = cols)\n",
    "    page = page_num\n",
    "    #Top Table\n",
    "\n",
    "    left = 7.92\n",
    "    right = 559.44\n",
    "\n",
    "    y_1 = df.loc[df['Text'] == \"Last Raced\",'y_1'].tolist()[0] #Getting y_1 value\n",
    "    top = (((729 - y_1) * 11)/792) *72\n",
    "\n",
    "    y_1 = df.loc[df['Text'] == \"Fractional Times\",'y_1'].tolist()[0]\n",
    "    bottom = (((729 - y_1) * 11)/792 + .50) *72\n",
    "\n",
    "    #Adding Table 1 to df\n",
    "    table_loc_df.loc[len(table_loc_df.index)] =[page,1,top,left,bottom,right]\n",
    "\n",
    "    #Bottom Table\n",
    "\n",
    "    left = 126\n",
    "    right = 424.08\n",
    "\n",
    "    y_1 = df.loc[df['Text'].str.contains(\"Past Performance\"),'y_1'].tolist()[0]\n",
    "    top = (((729 - y_1) * 11)/792) * 72\n",
    "\n",
    "\n",
    "    y_1 = df.loc[df['Text'] == \"Trainers\",'y_1'].tolist()[0]\n",
    "    bottom = ((((729 - y_1) * 11)/792 + .75)) * 72\n",
    "\n",
    "    #Adding Table 2 to df\n",
    "    table_loc_df.loc[len(table_loc_df.index)] =[page,2,top,left,bottom,right]\n",
    "    return table_loc_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3be71f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets the non-empty pages and number of horses per page\n",
    "\n",
    "from PyPDF2 import PdfReader\n",
    "def get_page_list(file):  #Pdf file\n",
    "    reader = PdfReader(file)\n",
    "    num_pages = len(reader.pages)\n",
    "    \n",
    "    \n",
    "    page_list = []\n",
    "    for page_num in range(1,num_pages + 1):\n",
    "        page = reader.pages[page_num - 1]\n",
    "        text = page.extract_text()\n",
    "        tokenized_text = text.split()\n",
    "\n",
    "        start_count_bool = False\n",
    "        count = 0\n",
    "        for i in range(0,len(tokenized_text) - 1):\n",
    "            if(tokenized_text[i] == \"Trainers:\"):\n",
    "                start_count_bool = True\n",
    "            elif(tokenized_text[i] == \"Owners:\"):\n",
    "                start_count_bool = False\n",
    "            elif(start_count_bool and tokenized_text[i] == '-'):\n",
    "                count += 1\n",
    "\n",
    "        if count > 0:\n",
    "            page_list.append({'page_num' : page_num, 'horse_count' : count})\n",
    "    return page_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d0d8d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets a table from a pdf, using a dataframe of rough locations of the tables on the pdf\n",
    "#Returns a dataframe of the table\n",
    "#Step 4 of table parsing\n",
    "\n",
    "\n",
    "def get_table(file,\n",
    "              table_loc_df, #Dataframe of locations of tables on pdf\n",
    "              table_num, #Table we are parsing for (1 = top, 2 = bottom)\n",
    "              page, #Page number\n",
    "              num_horses): #Number of horses on page\n",
    "    print(\"Looking for tables...\")\n",
    "    #Setting variables \n",
    "    num_target_rows = num_horses * 2\n",
    "    test_area =[\n",
    "            table_loc_df.iloc[table_num - 1,2],\n",
    "            table_loc_df.iloc[table_num - 1,3],\n",
    "            table_loc_df.iloc[table_num - 1,4],\n",
    "            table_loc_df.iloc[table_num - 1,5]\n",
    "        ]\n",
    "    \n",
    "    #Initial table scan\n",
    "    try:\n",
    "        scan_df = tabula.read_pdf(file, pages = page, area = [test_area])\n",
    "        table_df = scan_df[0]\n",
    "        col_names = list(table_df.columns.values)\n",
    "        num_rows = len(table_df.index)\n",
    "    except:\n",
    "        print(\"Couldn't read a table from default area\")\n",
    "        col_names = [\"top_not_found\"]\n",
    "        num_rows = 0\n",
    "        \n",
    "    #Finding top bound\n",
    "    \n",
    "    \n",
    "    #Setting header value to look for\n",
    "    if(table_num == 1):\n",
    "        target_header = 'Last Raced'\n",
    "    else:\n",
    "        target_header = 'Pgm'\n",
    "        \n",
    "\n",
    "    \n",
    "    #Loop until top bound is right\n",
    "    bound_num = 0 #Increased bounds by 10, both positive and negative to find the right headers. Ex: 10, -10, 20, -20, 30...\n",
    "    top_bound = table_loc_df.iloc[table_num - 1,2]\n",
    "    while(col_names[0] != target_header or bound_num > 200):    \n",
    "        top_bound = table_loc_df.iloc[table_num - 1,2]\n",
    "        top_bound += bound_num\n",
    "        test_area[0] = top_bound\n",
    "        try:\n",
    "            scan_df = tabula.read_pdf(file, pages = page, area = [test_area])\n",
    "            table_df = scan_df[0]\n",
    "        except:\n",
    "            print(\"Couldn't read a table, moving on from {} top_bound\".format(top_bound))\n",
    "            \n",
    "        col_names = list(table_df.columns.values)\n",
    "\n",
    "        #Change bound_num\n",
    "        if(bound_num <= 0): #If number is in negative cycle\n",
    "            bound_num *= -1\n",
    "            bound_num += 10\n",
    "        else:\n",
    "            bound_num *= -1\n",
    "    \n",
    "    if(bound_num > 200):\n",
    "        print(\"Error: Couldn't find top bound\")\n",
    "        return\n",
    "    else:\n",
    "        print(\"Found table top bound at {}\".format(top_bound))\n",
    "        table_loc_df.iloc[table_num - 1, 2] = top_bound #Adding new top bound to df\n",
    "    \n",
    "    #Finding bottom bound\n",
    "\n",
    "    bound_num = 0 #Increased bounds by 10, both positive and negative to find the right headers. Ex: 10, -10, 20, -20, 30...\n",
    "    bottom_bound = table_loc_df.iloc[table_num - 1,4]\n",
    "    while(num_rows != num_target_rows or bound_num > 200):\n",
    "        bottom_bound = table_loc_df.iloc[table_num - 1,4]\n",
    "        bottom_bound += bound_num\n",
    "        test_area[2] = bottom_bound\n",
    "        if(bottom_bound > 0):\n",
    "            try:\n",
    "                scan_df = tabula.read_pdf(file, pages = page, area = [test_area])\n",
    "                table_df = scan_df[0]\n",
    "            except:\n",
    "                print(\"Couldn't read a table, moving on from {} bottom_bound\".format(bottom_bound))\n",
    "\n",
    "            num_rows = len(table_df.index)\n",
    "\n",
    "         #Change bound_num\n",
    "        if(bound_num <= 0): #If number is in negative cycle\n",
    "            bound_num *= -1\n",
    "            bound_num += 10\n",
    "        else:\n",
    "            bound_num *= -1\n",
    "    \n",
    "    if(bound_num > 200):\n",
    "        print(\"Error: Couldn't find bottom bound\")\n",
    "    else:\n",
    "        table_loc_df.iloc[table_num - 1, 4] = bottom_bound #Adding new bottom bound to df\n",
    "        print(\"Found table bottom bound at {}\".format(bottom_bound))\n",
    "        return table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81f6dddc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PDF <_io.BufferedReader name='equibaseFile.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'page_num': 1, 'horse_count': 5}, {'page_num': 2, 'horse_count': 7}, {'page_num': 3, 'horse_count': 5}, {'page_num': 4, 'horse_count': 6}, {'page_num': 5, 'horse_count': 8}, {'page_num': 6, 'horse_count': 7}, {'page_num': 7, 'horse_count': 5}, {'page_num': 8, 'horse_count': 8}, {'page_num': 9, 'horse_count': 8}, {'page_num': 10, 'horse_count': 8}, {'page_num': 11, 'horse_count': 5}]\n",
      "Page num:  1\n",
      "Looking for tables...\n",
      "Found table top bound at 135.24599999999995\n",
      "Found table bottom bound at 206.54599999999994\n",
      "Looking for tables...\n",
      "Found table top bound at 404.8310000000001\n",
      "Found table bottom bound at 479.4650000000001\n",
      "Page num:  2\n",
      "Looking for tables...\n",
      "Found table top bound at 125.82999999999993\n",
      "Found table bottom bound at 207.13\n",
      "Looking for tables...\n",
      "Found table top bound at 404.83\n",
      "Found table bottom bound at 498.108\n",
      "Page num:  3\n",
      "Looking for tables...\n",
      "Found table top bound at 109.68599999999992\n",
      "Found table bottom bound at 179.54599999999994\n",
      "Looking for tables...\n",
      "Found table top bound at 350.30600000000004\n",
      "Found table bottom bound at 424.94\n",
      "Page num:  4\n",
      "Looking for tables...\n",
      "Found table top bound at 134.538\n",
      "Found table bottom bound at 215.83799999999997\n",
      "Looking for tables...\n",
      "Found table top bound at 420.765\n",
      "Found table bottom bound at 505.39900000000006\n",
      "Page num:  5\n",
      "Looking for tables...\n",
      "Found table top bound at 134.12199999999996\n",
      "Found table bottom bound at 225.42199999999988\n",
      "Looking for tables...\n",
      "Found table top bound at 496.581\n",
      "Found table bottom bound at 591.215\n",
      "Page num:  6\n",
      "Looking for tables...\n",
      "Found table top bound at 143.82999999999993\n",
      "Found table bottom bound at 225.13\n",
      "Looking for tables...\n",
      "Found table top bound at 456.749\n",
      "Found table bottom bound at 541.383\n",
      "Page num:  7\n",
      "Looking for tables...\n",
      "Found table top bound at 144.24599999999998\n",
      "Found table bottom bound at 215.54599999999994\n",
      "Looking for tables...\n",
      "Found table top bound at 402.869\n",
      "Found table bottom bound at 477.563\n",
      "Page num:  8\n",
      "Looking for tables...\n",
      "Found table top bound at 143.12199999999996\n",
      "Found table bottom bound at 234.42199999999988\n",
      "Looking for tables...\n",
      "Found table top bound at 447.933\n",
      "Found table bottom bound at 542.567\n",
      "Page num:  9\n",
      "Looking for tables...\n",
      "Found table top bound at 152.12199999999996\n",
      "Found table bottom bound at 243.42199999999988\n",
      "Looking for tables...\n",
      "Found table top bound at 403.997\n",
      "Found table bottom bound at 506.567\n",
      "Page num:  10\n",
      "Looking for tables...\n",
      "Found table top bound at 143.12199999999996\n",
      "Found table bottom bound at 234.42199999999988\n",
      "Looking for tables...\n",
      "Found table top bound at 439.997\n",
      "Found table bottom bound at 542.567\n",
      "Page num:  11\n",
      "Looking for tables...\n",
      "Found table top bound at 135.24599999999995\n",
      "Found table bottom bound at 206.54599999999994\n",
      "Looking for tables...\n",
      "Found table top bound at 445.3310000000001\n",
      "Found table bottom bound at 519.965\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pdf = \"equibaseFile.pdf\"\n",
    "df_list = []\n",
    "page_list = get_page_list(pdf)\n",
    "print(page_list)\n",
    "#Extract words on position\n",
    "pages = extract_pages(pdf)\n",
    "full_text_loc_df = extract_to_df(pages)\n",
    "for page in page_list: #Get both tables for each page\n",
    "    print(\"Page num: \" ,page[\"page_num\"])\n",
    "    #try:\n",
    "    text_loc_df = create_text_loc_df(page['page_num'],full_text_loc_df) #Locations of key text on page\n",
    "    table_loc_df = table_location_to_df(page['page_num'],text_loc_df) #Locations of tables on page\n",
    "    top_table = get_table(pdf,table_loc_df,1,page['page_num'],page['horse_count']) #Getting top table\n",
    "    bottom_table = get_table(pdf,table_loc_df,2,page['page_num'],page['horse_count']) #Getting bottom table\n",
    "        #Add to list of dfs\n",
    "    df_list.append(top_table)\n",
    "    df_list.append(bottom_table)\n",
    "    #except:\n",
    "        #print(\"Error with page\", page[\"page_num\"])\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5339d3d",
   "metadata": {},
   "source": [
    "Cleaning Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f268ee53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top Table\n",
    "\n",
    "def clean_top_table(df): #df of top table to be cleaned\n",
    "    #Merging super scripts\n",
    "    script_df = df.loc[df['Pgm'].isnull()]\n",
    "    \n",
    "    #Get col names of race partitions\n",
    "    start_index = script_df.columns.get_loc('Start')\n",
    "    end_index = script_df.columns.get_loc('Odds')\n",
    "    \n",
    "    col_name_list = script_df.columns[start_index + 1:end_index]\n",
    "    col_name_list = [*['Last Raced'],*col_name_list]\n",
    "     \n",
    "    script_df = script_df.loc[:,col_name_list]\n",
    "    \n",
    "    col_name_list[0] = col_name_list[0] + '_super_script'\n",
    "    for i in range (1,len(col_name_list)):\n",
    "        col_name_list[i] = col_name_list[i] + '_length_behind'\n",
    "    script_df.columns = col_name_list\n",
    "    \n",
    "    df_horses = df.loc[df['Pgm'].isnull()==False].reset_index(drop=False)\n",
    "    script_df.reset_index(drop = True, inplace = True)\n",
    "    final_df = df_horses.merge(script_df,left_index=True,right_index=True,how='left')\n",
    "\n",
    "    #Splitting Wgt and M/E\n",
    "    final_df[['Wgt', 'M/E']] = final_df['Wgt M/E'].str.split(' ', 1,expand = True)\n",
    "\n",
    "    #Removing unnamed & old index\n",
    "    final_df.drop(['index', 'Wgt M/E'], axis = 1, inplace = True)\n",
    "\n",
    "    #Removing unnamed\n",
    "    end_index = final_df.columns.get_loc('Pgm')\n",
    "    for i in range(1,end_index):\n",
    "        final_df.drop(final_df.columns[1],axis = 1, inplace = True)\n",
    "        \n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5fdb4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_bottom_table(df): #df of top table to be cleaned\n",
    "    #Merging super scripts\n",
    "    script_df = df.loc[df['Pgm'].isnull()]\n",
    "  \n",
    "    #Get col names of race partitions\n",
    "    start_index = script_df.columns.get_loc('Start')\n",
    "    end_index = script_df.columns.get_loc('Fin') + 1\n",
    "    \n",
    "    col_name_list = script_df.columns[start_index + 1:end_index]\n",
    "    \n",
    "    col_name_list = [*col_name_list]\n",
    "    script_df = script_df.loc[:,col_name_list]\n",
    "    \n",
    "\n",
    "    for i in range (0,len(col_name_list)):\n",
    "        col_name_list[i] = col_name_list[i] + '_length_behind'\n",
    "    script_df.columns = col_name_list\n",
    "\n",
    "    df_horses = df.loc[df['Pgm'].isnull()==False].reset_index(drop=False)\n",
    "    script_df.reset_index(drop = True, inplace = True)\n",
    "    final_df = df_horses.merge(script_df,left_index=True,right_index=True,how='left')\n",
    "\n",
    "    df_horses = df.loc[df['Pgm'].isnull()==False].reset_index(drop=False)\n",
    "    final_df = df_horses.merge(script_df,left_index=True,right_index=True,how='left')\n",
    "\n",
    "\n",
    "    #Removing old index\n",
    "    final_df.drop('index', axis = 1, inplace = True)\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5de1f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pgm</th>\n",
       "      <th>Horse Name</th>\n",
       "      <th>Start</th>\n",
       "      <th>1/4</th>\n",
       "      <th>1/2</th>\n",
       "      <th>Str</th>\n",
       "      <th>Fin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/2</td>\n",
       "      <td>2 1/2</td>\n",
       "      <td>1 1/2</td>\n",
       "      <td>1 1/2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Kirtan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/2</td>\n",
       "      <td>2 1/2</td>\n",
       "      <td>1 1/2</td>\n",
       "      <td>1 1/2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Be Like Beth</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1 1/2</td>\n",
       "      <td>2 1/2</td>\n",
       "      <td>4 1/2</td>\n",
       "      <td>4 1/2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Pony Girl</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1 1/2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Sedona Rocks</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2 1/2</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>31 3/4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.0</td>\n",
       "      <td>Gwynedd</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pgm    Horse Name  Start    1/4    1/2    Str     Fin\n",
       "0  NaN           NaN    NaN    1/2  2 1/2  1 1/2   1 1/2\n",
       "1  5.0        Kirtan    1.0      1      1      1       1\n",
       "2  NaN           NaN    NaN    1/2  2 1/2  1 1/2   1 1/2\n",
       "3  3.0  Be Like Beth    2.0      2      3      2       2\n",
       "4  NaN           NaN    NaN  1 1/2  2 1/2  4 1/2   4 1/2\n",
       "5  1.0     Pony Girl    3.0      3      2      3       3\n",
       "6  NaN           NaN    NaN  1 1/2      5      5       5\n",
       "7  4.0  Sedona Rocks    4.0      4      4      4       4\n",
       "8  NaN           NaN    NaN  2 1/2      9     20  31 3/4\n",
       "9  6.0       Gwynedd    5.0      5      5      5       5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e164ef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean all dataframes in first pdf\n",
    "\n",
    "cleaned_df_list = []\n",
    "for i in range (len(df_list)):\n",
    "    if(i % 2 == 0): #If even\n",
    "        try:\n",
    "            cleaned_df_list.append(clean_top_table(df_list[i]))\n",
    "        except:\n",
    "            print(\"Error with df \", i)\n",
    "            cleaned_df_list.append(df_list[i])\n",
    "    else:\n",
    "        try:\n",
    "            cleaned_df_list.append(clean_bottom_table(df_list[i]))\n",
    "        except:\n",
    "            print(\"Error with df\", i)\n",
    "            cleaned_df_list.append(df_list[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7593bc43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pgm</th>\n",
       "      <th>Horse Name</th>\n",
       "      <th>Start</th>\n",
       "      <th>1/4</th>\n",
       "      <th>1/2</th>\n",
       "      <th>Str</th>\n",
       "      <th>Fin</th>\n",
       "      <th>1/4_length_behind</th>\n",
       "      <th>1/2_length_behind</th>\n",
       "      <th>Str_length_behind</th>\n",
       "      <th>Fin_length_behind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Kirtan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1/2</td>\n",
       "      <td>2 1/2</td>\n",
       "      <td>1 1/2</td>\n",
       "      <td>1 1/2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Be Like Beth</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1/2</td>\n",
       "      <td>2 1/2</td>\n",
       "      <td>1 1/2</td>\n",
       "      <td>1 1/2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Pony Girl</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1 1/2</td>\n",
       "      <td>2 1/2</td>\n",
       "      <td>4 1/2</td>\n",
       "      <td>4 1/2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Sedona Rocks</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1 1/2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>Gwynedd</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2 1/2</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>31 3/4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pgm    Horse Name  Start 1/4 1/2 Str Fin 1/4_length_behind  \\\n",
       "0  5.0        Kirtan    1.0   1   1   1   1               1/2   \n",
       "1  3.0  Be Like Beth    2.0   2   3   2   2               1/2   \n",
       "2  1.0     Pony Girl    3.0   3   2   3   3             1 1/2   \n",
       "3  4.0  Sedona Rocks    4.0   4   4   4   4             1 1/2   \n",
       "4  6.0       Gwynedd    5.0   5   5   5   5             2 1/2   \n",
       "\n",
       "  1/2_length_behind Str_length_behind Fin_length_behind  \n",
       "0             2 1/2             1 1/2             1 1/2  \n",
       "1             2 1/2             1 1/2             1 1/2  \n",
       "2             2 1/2             4 1/2             4 1/2  \n",
       "3                 5                 5                 5  \n",
       "4                 9                20            31 3/4  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df_list[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbd4dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
