{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80944ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "import re\n",
    "import json\n",
    "from IPython.core.debugger import set_trace\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3dfd81df",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('race_types.json') as json_file:\n",
    "    race_types = json.load(json_file)\n",
    "race_types_dict = race_types[\"race_types\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "450eb651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of tracks using track_data\n",
    "track_list = []\n",
    "with open('../PDFDownloader/track_data.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    track_data = data['tracks']\n",
    "for track in track_data:\n",
    "    track_list.append(track[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b62d1ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns header_scanner dictionary of header scanning tools\n",
    "#header_scaner[\"split_word\"]: Word to split pdf on after criteria. Purse or Price\n",
    "#header_scanner[\"word_list\"]: Tuple that contains keywords, startword, endword, and if either is inclusive via numeric code\n",
    "\n",
    "race_types = [\n",
    "    \"allowance\",\n",
    "    \"allowance claiming\",\n",
    "    \"claiming\",\n",
    "    \"maiden claiming\",\n",
    "    \"maiden special weight\",\n",
    "    \"stakes\",\n",
    "    \"starter allowance\",\n",
    "    \"starter optional claiming\"\n",
    "]\n",
    "\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "\n",
    "def get_race_type(text):\n",
    "    #Get race type in lowercase from text\n",
    "    race_type =  text.split(\"\\n\")[1].split(\"-\")[0].lower()\n",
    "    \n",
    "    #In the case of stakes, get rid of qualifier \n",
    "    if(race_type.split()[0] == 'stakes'):\n",
    "        race_type = \"stakes\"\n",
    "    print(race_type)\n",
    "    \n",
    "    #Find most simlar race type\n",
    "    best_score = 0\n",
    "    best_index = -1\n",
    "    for i in range(len(race_types)):\n",
    "        score = similar(race_type, race_types[i]) * 100\n",
    "        print(race_types[i], score)\n",
    "        if(score > best_score):\n",
    "            best_score = score\n",
    "            best_index = i\n",
    "    race_type = race_types[best_index]\n",
    "    return race_types_dict[race_type]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dc4bc5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maiden \n",
      "allowance 25.0\n",
      "allowance claiming 24.0\n",
      "claiming 40.0\n",
      "maiden claiming 63.63636363636363\n",
      "maiden special weight 50.0\n",
      "stakes 30.76923076923077\n",
      "starter allowance 25.0\n",
      "starter optional claiming 18.75\n",
      "{'type': 'maiden claiming', 'word_list': [['track', '', '-', 1], ['date', '-', '-'], ['race_num', 'Race', 'MAIDEN'], ['criteria', 'Thoroughbred', '.', 2], ['claiming_price', 'Price', '0', 2], ['track_length', '0', 'Current'], ['purse', 'Purse', '0', 2], ['weather', 'Weather', 'Track'], ['track_type', 'Track', 'Off'], ['off_time', 'at', 'Start'], ['start', 'Start', 'Timer']], 'split_word': 'Price'}\n"
     ]
    }
   ],
   "source": [
    "race_type =  text.split(\"\\n\")[1].split(\"-\")[0].lower()\n",
    "\n",
    "print(get_race_type(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "037cdc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_count = 0\n",
    "i = -1\n",
    "while i < len(tokenized_text) - 1:\n",
    "    i+=1 #Increment at start of loop\n",
    "    keyword_tuple = word_list[keyword_count]\n",
    "    if tokenized_text[i].__contains__(keyword_tuple[1]): #If startword is found\n",
    "        value_string = \"\" #Start of string\n",
    "        keyword = keyword_tuple[0] #Save keyword\n",
    "        if len(keyword_tuple) > 3 and keyword_tuple[3] != 2:#Checking if start is inclusive\n",
    "            next_word = tokenized_text[i] #Increment to next word (inclusive)\n",
    "        else:\n",
    "            i += 1\n",
    "            next_word = tokenized_text[i] #Increment to next word (exclusive)\n",
    "        while not(next_word.__contains__(keyword_tuple[2])) and i < len(tokenized_text) - 1:\n",
    "            value_string = value_string + \" \" + next_word\n",
    "            i += 1\n",
    "            next_word = tokenized_text[i]\n",
    "        if len(keyword_tuple) > 3 and keyword_tuple[3] != 1: #Checking if end is inclusive\n",
    "            value_string = value_string + \" \" + next_word\n",
    "            i -= 1\n",
    "        else: #End is exclusive, decrement by 1 to start at this word next loop\n",
    "            i -= 1\n",
    "        top_fields.update({keyword: value_string}) #Add to dictionary\n",
    "        keyword_count+=1 #Increment to next keyword\n",
    "    if keyword_count >= len(word_list): #Check if keywords are filled\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c92a50da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maiden special weight \n",
      "allowance 25.806451612903224\n",
      "allowance claiming 20.0\n",
      "claiming 26.666666666666668\n",
      "maiden claiming 59.45945945945946\n",
      "maiden special weight 97.67441860465115\n",
      "stakes 21.428571428571427\n",
      "starter allowance 35.8974358974359\n",
      "starter optional claiming 34.04255319148936\n"
     ]
    }
   ],
   "source": [
    "top_fields = {}\n",
    "#pdf = \"AJX_09_14_2022.pdf\"\n",
    "pdf = \"Error_PDFS/AQU_11_04_2022.pdf\"\n",
    "\n",
    "reader = PdfReader(pdf) #File to be scanned\n",
    "number_of_pages = len(reader.pages) #Number of pages\n",
    "page = reader.pages[0] #Page to be scanned\n",
    "\n",
    "\n",
    "text = page.extract_text()\n",
    "#Get race type here\n",
    "race_type =  text.split(\"\\n\")[1].split(\"-\")[0].lower()\n",
    "race_type_dict = get_race_type(text)\n",
    "word_list = race_type_dict[\"word_list\"]\n",
    "split_word = race_type_dict[\"split_word\"]\n",
    "\n",
    "\n",
    "\n",
    "initial_split = text.split(\"VideoRaceReplay\")\n",
    "text = initial_split[0]\n",
    "split_cap = text.split(split_word) #Spliting \n",
    "\n",
    "#Top, capitalized section\n",
    "top_text = split_cap[0]\n",
    "\n",
    "#Bottom, post price section\n",
    "bottom_text = \"\"\n",
    "for i in range(1,len(split_cap)):\n",
    "    bottom_text += split_cap[i]\n",
    "    \n",
    "#tokenized_bottom_text = re.findall('[A-Z][^A-Z]*', bottom_text) #Split on capital letters\n",
    "tokenized_bottom_text = [s for s in re.split(\"([A-Z][^A-Z]*)\", bottom_text) if s]\n",
    "\n",
    "#Adding text back together\n",
    "top_text += \" {}\".format(split_word)\n",
    "for i in range(len(tokenized_bottom_text)):\n",
    "    top_text += \" {}\".format(tokenized_bottom_text[i])\n",
    "\n",
    "    \n",
    "tokenized_text = top_text.replace(':',' ').split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8bbc733f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A?Queduct\n"
     ]
    }
   ],
   "source": [
    "#Cleaing results\n",
    "for key in top_fields.keys():\n",
    "    value = top_fields[key]\n",
    "    value = value.lstrip() #Gets rid of starting spaces\n",
    "    value = value.replace(\".\",\"\")\n",
    "    top_fields[key] = value\n",
    "\n",
    "top_fields['off_time'] = top_fields['off_time'].replace(\" \", \":\")  #Changes to readable time\n",
    "\n",
    "#Cleans often too long length of track string\n",
    "nums = [\"One\", \"Two\", \"Three\", \"Four\", \"Five\",\"Six\", \"Seven\",\"Eigth\",\"Nine\"] #Assist on cleaning track\n",
    "length_str = top_fields['track_length'].split(\" \")\n",
    "index = 0\n",
    "found_flag = False\n",
    "for i in range(len(length_str)):\n",
    "    for num_word in nums:\n",
    "        if(length_str[i] == num_word):\n",
    "            index = i\n",
    "            found_flag = True\n",
    "            break\n",
    "    if(found_flag):\n",
    "        break\n",
    "final_str = \"\"\n",
    "for i in range(i,len(length_str)):\n",
    "    final_str += \" {}\".format(length_str[i])\n",
    "top_fields['track_length'] = final_str\n",
    "\n",
    "\n",
    "#Cleaning track name\n",
    "current_name = top_fields['track'].title()\n",
    "print(current_name)\n",
    "best_score = 0\n",
    "best_name = current_name\n",
    "for track_name in track_list:\n",
    "    score = similar(current_name,track_name) * 100\n",
    "    if(score > best_score):\n",
    "        best_score = score\n",
    "        best_name = track_name\n",
    "top_fields['track'] = best_name\n",
    "\n",
    "#Adding race type\n",
    "top_fields['race_type'] = race_type_dict['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9551d341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "track : Aqueduct\n",
      "date : November 4, 2022\n",
      "race_num : 1\n",
      "criteria : (UP TO $14,790 NYSBFOA) FOR MAIDENS, FILLIES TWO YEARS OLD\n",
      "weight : 119 lbs\n",
      "track_length :  One Mile On The Dirt\n",
      "purse : $85,000\n",
      "weather : Clear\n",
      "track_type : Fast\n",
      "off_time : 11:38\n",
      "start : Good for all except 2,6\n",
      "race_type : maiden special weight\n"
     ]
    }
   ],
   "source": [
    "for field,value in top_fields.items():\n",
    "    print(field ,':', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b09b85a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
